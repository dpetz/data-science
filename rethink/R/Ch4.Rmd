---
title: "Chapter 4"
output: html_notebook
---

# Linear model of height

Load *!KungSan* data set created from field interviews by *Nancy Howell* in the 1960s:
```{r}
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
```
To get started, model without predictors.
$\mu$ has no subscript so its the same estimate for all observations.
Height is like many measures in nature normal distributed because it may be seen as the result
of a series of small biological steps. Suming those "samples" up from any distribution yields
a normal distribution ([Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem))

$$
h_i \sim Normal(\mu,\sigma) \\
\mu \sim Normal(178,20) \\
\sigma \sim Uniform(0,50)
$$

I use my height as prior for mean. A $\sigma$ of 20 encodes that 95% of individuals are at least 158cm and at most 189cm. Plot the priors:
```{r}
par(mfrow=c(1,2))
curve(dunif(x,0,50),from=-10,to=60)
curve(dnorm(x,178,20),from=100,to=250)
```

Simulate height by sampling from prior: 
```{r}
sample_mu <- rnorm(1e4,178,20)
sample_sigma <- runif(1e4,0,50)
prior_h <- rnorm(1e4,sample_mu,sample_sigma)
dens(prior_h)
```

# Posterior Distribution

## Grid Approximation

In simple cases like this the posterior distribution can be mapped via
brute force calculation:
```{r}
post.grid <- function(heights,mu.from=140,mu.to=160,sigma.from=4,sigma.to=9) {
  # Produce every mu-sigma-combination.
  post <- expand.grid(
    mu=seq( from=mu.from , to=mu.to, length.out=1000 ), 
    sigma=seq( from=sigma.from , to=sigma.to, length.out=200 )
    )
  
  # Calculate log-likelihood (log to avoid rounding errors)
  post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
    heights,
    mean=post$mu[i],
    sd=post$sigma[i],
    log=TRUE ) ) )
  
  # Multiply priors with likelihoods (ie. add at log scale)
  post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
    dunif( post$sigma , 0 , 50 , TRUE  )
  
  # Every parameter sample has almost zero probability so we
  # rescale them for relative comparison (ie. no longer pobabilities)
  post$prob <- exp( post$prod - max(post$prod) )
  
  post
}
d2 <- d [ d$age >= 18 , ]
post2 <- post.grid(d2$height)
image_xyz( post2$mu , post2$sigma , post2$prob,
  xlab=expression(mu), ylab=expression(sigma) )
```

# Sample from the Posterior

```{r}
post.sample <- function(post) {
  sample.rows <- sample( 1:nrow(post) , size=1e4 , replace=TRUE , prob=post$prob )
  sample.mu <- post$mu[ sample.rows ]
  sample.sigma <- post$sigma[ sample.rows ]
  data.frame(mu=sample.mu,sigma=sample.sigma)
}
sample2 <- post.sample(post2)
plot( sample2$mu , sample2$sigma , cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1) )
```

Parameter estimates have higher uncertainty if we repeat with just a few observations.
Tails are more heavy, in particular $\sigma$'s right-hand side tail.

```{r}
d3 <- sample(d2$height,size=20)
post3 <- post.grid(d3)
sample3 <- post.sample(post3)
par(mfrow=c(2,2))
dens(cbind(sample2,sample3),norm.comp=TRUE,show.HPDI=0.89)
```