library(rethinking)
data(Howell1)
d <- Howell1
str(d)
par(mfrow=c(1,2))
curve(dunif(x,0,50),from=-10,to=60)
curve(dnorm(x,178,20),from=100,to=250)
sample_mu <- rnorm(1e4,178,20)
sample_sigma <- runif(1e4,0,50)
prior_h <- rnorm(1e4,sample_mu,sample_sigma)
dens(prior_h)
d2 <- d [ d$age >= 18 , ]
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
par(mfrow=c(1,2))
curve(dunif(x,0,50),from=-10,to=60)
curve(dnorm(x,178,20),from=100,to=250)
sample_mu <- rnorm(1e4,178,20)
sample_sigma <- runif(1e4,0,50)
prior_h <- rnorm(1e4,sample_mu,sample_sigma)
dens(prior_h)
d2 <- d [ d$age >= 18 , ]
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
par(mfrow=c(1,2))
curve(dunif(x,0,50),from=-10,to=60)
curve(dnorm(x,178,20),from=100,to=250)
sample_mu <- rnorm(1e4,178,20)
sample_sigma <- runif(1e4,0,50)
prior_h <- rnorm(1e4,sample_mu,sample_sigma)
dens(prior_h)
d2 <- d [ d$age >= 18 , ]
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
---
title: "Getting Started"
output: html_notebook
---
---
title: "Getting Started"
output: html_notebook
---
Examples from [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/).
Markdown [cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)
To render html in GitHub prefix `https://htmlpreview.github.io/?` to URL.
Update R version (currently `3.6.2.`and install book packages:
```
install.packages(c("coda","mvtnorm","devtools"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
```
install.packages(c("coda", "mvtnorm", "devtools"))
---
title: "Chapter 3"
output: html_notebook
---
# Water
### Data Story
* Globe with proportion $p$ of water $W$
* Throw & catch globe and put finger at random place has probability     $p$ of water $W$ or probability $(1-p)$ of land $L$
* Tosses are independent
### Grid approximation of posterior
Likelihood is binomial distributed.
```{r}
plot_posterior_grid <- function(prior) {
likelihood <- dbinom(6, size=9, prob=p_grid)
unstd.posterior <- likelihood * prior
posterior <- unstd.posterior / sum(unstd.posterior)
plot(p_grid,posterior,type='b', xlab='probability of water', ylab='posterior probability')
mtext("20 points")
}
plot_posterior_grid( rep(1,20) )
```
I know world has more than 50% qwater:
```{r}
prior <- ifelse( p_grid < 0.5, 0, 1 )
plot_posterior_grid( prior )
```
If I believed 50% is most likely:
```{r}
prior <- exp( -5*abs( p_grid - 0.5 ) )
plot_posterior_grid( prior )
```
plot_posterior_grid <- function(prior) {
likelihood <- dbinom(6, size=9, prob=p_grid)
unstd.posterior <- likelihood * prior
posterior <- unstd.posterior / sum(unstd.posterior)
plot(p_grid,posterior,type='b', xlab='probability of water', ylab='posterior probability')
mtext("20 points")
}
plot_posterior_grid( rep(1,20) )
plot_posterior_grid <- function(prior) {
likelihood <- dbinom(6, size=9, prob=p_grid)
unstd.posterior <- likelihood * prior
posterior <- unstd.posterior / sum(unstd.posterior)
plot(p_grid,posterior,type='b', xlab='probability of water', ylab='posterior probability')
mtext("20 points")
}
plot_posterior_grid( rep(1,20) )
p_grid <- seq( from=0 , to=1 , length.out=20  )
posterior_grid <- function(prior) {
likelihood <- dbinom(6, size=9, prob=p_grid)
unstd.posterior <- likelihood * prior
posterior <- unstd.posterior / sum(unstd.posterior)
plot(p_grid,posterior,type='b', xlab='probability of water', ylab='posterior probability')
mtext("20 points")
}
posterior_grid( rep(1,20) )
prior <- ifelse( p_grid < 0.5, 0, 1 )
plot_posterior_grid( prior )
prior <- ifelse( p_grid < 0.5, 0, 1 )
posterior_grid( prior )
prior <- ifelse( p_grid < 0.5, 0, 1 )
posterior_grid( prior )
prior <- exp( -5*abs( p_grid - 0.5 ) )
plot_posterior_grid( prior )
prior <- ifelse( p_grid < 0.5, 0, 1 )
posterior_grid( prior )
prior <- exp( -5*abs( p_grid - 0.5 ) )
plot_posterior_grid( prior )
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
par(mfrow=c(1,2))
curve(dunif(x,0,50),from=-10,to=60)
curve(dnorm(x,178,20),from=100,to=250)
sample_mu <- rnorm(1e4,178,20)
sample_sigma <- runif(1e4,0,50)
prior_h <- rnorm(1e4,sample_mu,sample_sigma)
dens(prior_h)
d2 <- d [ d$age >= 18 , ]
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
d2 <- d [ d$age >= 18 , ]
mu.list <- seq( from=140 , to=160, length.out=200 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative values (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
contour_xyz( post$mu , post$sigma , post$prob,
xlab=expression(mu), ylab=expression(sigma) )
sample.rows <- sample( 1:nrow(post) , size=1e4 , replace=TRUE , prob=post$prob )
sample.mu <- post$mu[ sample.rows ]
sample.sigma <- post$sigma[ sample.rows ]
plot( sample.mu , sample.sigma , cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1) )
d2 <- d [ d$age >= 18 , ]
mu.list <- seq( from=140 , to=160, length.out=2000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative values (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
contour_xyz( post$mu , post$sigma , post$prob,
xlab=expression(mu), ylab=expression(sigma) )
d2 <- d [ d$age >= 18 , ]
mu.list <- seq( from=140 , to=160, length.out=200 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative values (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
contour_xyz( post$mu , post$sigma , post$prob,
xlab=expression(mu), ylab=expression(sigma) )
sample.rows <- sample( 1:nrow(post) , size=1e4 , replace=TRUE , prob=post$prob )
sample.mu <- post$mu[ sample.rows ]
sample.sigma <- post$sigma[ sample.rows ]
plot( sample.mu , sample.sigma , cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1) )
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
par(mfrow=c(1,2))
curve(dunif(x,0,50),from=-10,to=60)
curve(dnorm(x,178,20),from=100,to=250)
sample_mu <- rnorm(1e4,178,20)
sample_sigma <- runif(1e4,0,50)
prior_h <- rnorm(1e4,sample_mu,sample_sigma)
dens(prior_h)
d2 <- d [ d$age >= 18 , ]
mu.list <- seq( from=140 , to=160, length.out=200 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative values (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
contour_xyz( post$mu , post$sigma , post$prob,
xlab=expression(mu), ylab=expression(sigma) )
sample.rows <- sample( 1:nrow(post) , size=1e4 , replace=TRUE , prob=post$prob )
sample.mu <- post$mu[ sample.rows ]
sample.sigma <- post$sigma[ sample.rows ]
plot( sample.mu , sample.sigma , cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1) )
View(post)
mu.list <- seq( from=140 , to=160, length.out=1000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (log to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative comparison (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
contour_xyz( post$mu , post$sigma , post$prob,
xlab=expression(mu), ylab=expression(sigma) )
mu.list <- seq( from=140 , to=160, length.out=1000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
mu.list <- seq( from=140 , to=160, length.out=1000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (log to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
mu.list <- seq( from=140 , to=160, length.out=1000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (log to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
mu.list <- seq( from=140 , to=160, length.out=1000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (log to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative comparison (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
mu.list <- seq( from=140 , to=160, length.out=1000 )
sigma.list <- seq( from=4 , to=9, length.out=200 )
# Produce every mu-sigma-combination.
post <- expand.grid( mu=mu.list, sigma=sigma.list )
# Calculate log-likelihood (log to avoid rounding errors)
post$LL <- sapply( 1:nrow(post), function(i) sum ( dnorm(
d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE ) ) )
# Multiply priors with likelihoods (ie. add at log scale)
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE  )
# Every parameter sample has almost zero probability so we
# rescale them for relative comparison (ie. no longer pobabilities)
post$prob <- exp( post$prod - max(post$prod) )
contour_xyz( post$mu , post$sigma , post$prob,
xlab=expression(mu), ylab=expression(sigma) )
View(post)
View(post)
